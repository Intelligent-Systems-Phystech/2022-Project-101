@article{litlink1,
      title={Unified Analysis of Stochastic Gradient Methods for Composite Convex and Smooth Optimization}, 
      author={Ahmed Khaled and Othmane Sebbouh and Nicolas Loizou and Robert M. Gower and Peter Richtárik},
      year={2020},
      eprint={2006.11573},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{litlink2,
      title={A Unified Theory of SGD: Variance Reduction, Sampling, Quantization and Coordinate Descent}, 
      author={Eduard Gorbunov and Filip Hanzely and Peter Richtárik},
      year={2019},
      eprint={1905.11261},
      archivePrefix={arXiv},
      primaryClass={math.OC}
}

@article{litlink3,
    title={A Superlinearly-Convergent Proximal Newton-type Method for the Optimization of Finite Sums},
    author={Anton Rodomanov and Dmitry Kropotov},
    booktitle={ICML},
    year={2016}
}

@article{litlink4,
  author    = {Dmitry Kovalev and
               Konstantin Mishchenko and
               Peter Richt{\'{a}}rik},
  title     = {Stochastic Newton and Cubic Newton Methods with Simple Local Linear-Quadratic
               Rates},
  journal   = {CoRR},
  volume    = {abs/1912.01597},
  year      = {2019},
  url       = {http://arxiv.org/abs/1912.01597},
  eprinttype = {arXiv},
  eprint    = {1912.01597},
  timestamp = {Thu, 02 Jan 2020 18:08:18 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1912-01597.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{litlink5,
      title={Parallel Coordinate Descent Methods for Big Data Optimization}, 
      author={Peter Richtárik and Martin Takáč},
      year={2013},
      eprint={1212.0873},
      archivePrefix={arXiv},
      primaryClass={math.OC}
}

@misc{litlink6,
      title={On Optimal Probabilities in Stochastic Coordinate Descent Methods}, 
      author={Peter Richtárik and Martin Takáč},
      year={2013},
      eprint={1310.3438},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{litlink7,
      title={Exact and Inexact Subsampled Newton Methods for Optimization}, 
      author={Raghu Bollapragada and Richard Byrd and Jorge Nocedal},
      year={2016},
      eprint={1609.08502},
      archivePrefix={arXiv},
      primaryClass={math.OC}
}


@article{svrg,
  author = {Rie Johnson and Tong Zhang},
  year = {2013},
  title = { Accelerating stochastic gradient descent using predictive variance reduction, Advances in Neural Information Processing Systems},
} 


@article{saga,
  author = {M. Schmidt and N. Le Roux and F. Bach},
  year = {2017},
  title = {Minimizing finite sums with the stochastic average gradient},
    journal = {Math. Program.},
     volume    = {162},
  number    = {1-2},
  pages     = {83--112},
  year      = {2017}
} 

@article{Doikov_2021,
	doi = {10.1007/s10957-021-01838-7},

	url = {https://doi.org/10.1007%2Fs10957-021-01838-7},

	year = 2021,
	month = {mar},

	publisher = {Springer Science and Business Media {LLC}
},

	volume = {189},

	number = {1},

	pages = {317--339},

	author = {Nikita Doikov and Yurii Nesterov},

	title = {Minimizing Uniformly Convex Functions by Cubic Regularization of Newton Method},

	journal = {Journal of Optimization Theory and Applications}
}

@misc{https://doi.org/10.48550/arxiv.1802.04084,
  doi = {10.48550/ARXIV.1802.04084},

  url = {https://arxiv.org/abs/1802.04084},

  author = {Doikov, Nikita and Richtárik, Peter},

  keywords = {Optimization and Control (math.OC), FOS: Mathematics, FOS: Mathematics},

  title = {Randomized Block Cubic Newton Method},

  publisher = {arXiv},

  year = {2018},

  copyright = {arXiv.org perpetual, non-exclusive license},
   keywords = {nocite}
}

@misc{https://doi.org/10.48550/arxiv.1905.11261,
  doi = {10.48550/ARXIV.1905.11261},

  url = {https://arxiv.org/abs/1905.11261},

  author = {Gorbunov, Eduard and Hanzely, Filip and Richtárik, Peter},

  keywords = {Optimization and Control (math.OC), Machine Learning (cs.LG), Numerical Analysis (math.NA), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences},

  title = {A Unified Theory of SGD: Variance Reduction, Sampling, Quantization and Coordinate Descent},

  publisher = {arXiv},

  year = {2019},

  copyright = {arXiv.org perpetual, non-exclusive license},
   keywords = {nocite}
}

@misc{https://doi.org/10.48550/arxiv.1603.09649,
  doi = {10.48550/ARXIV.1603.09649},

  url = {https://arxiv.org/abs/1603.09649},

  author = {Gower, Robert M. and Goldfarb, Donald and Richtárik, Peter},

  keywords = {Optimization and Control (math.OC), FOS: Mathematics, FOS: Mathematics, G.1.6, 90C53, 74S60, 90C06, 62L20, 68W20, 15B52, 65Y20, 68W40},

  title = {Stochastic Block BFGS: Squeezing More Curvature out of Data},

  publisher = {arXiv},

  year = {2016},

  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1506.02186,
  doi = {10.48550/ARXIV.1506.02186},

  url = {https://arxiv.org/abs/1506.02186},

  author = {Lin, Hongzhou and Mairal, Julien and Harchaoui, Zaid},

  keywords = {Optimization and Control (math.OC), FOS: Mathematics, FOS: Mathematics},

  title = {A Universal Catalyst for First-Order Optimization},

  publisher = {arXiv},

  year = {2015},

  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1602.00223,
  doi = {10.48550/ARXIV.1602.00223},

  url = {https://arxiv.org/abs/1602.00223},

  author = {Luo, Luo and Chen, Zihao and Zhang, Zhihua and Li, Wu-Jun},

  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},

  title = {A Proximal Stochastic Quasi-Newton Algorithm},

  publisher = {arXiv},

  year = {2016},

  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1305.3120,
  doi = {10.48550/ARXIV.1305.3120},

  url = {https://arxiv.org/abs/1305.3120},

  author = {Mairal, Julien},

  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), Optimization and Control (math.OC), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},

  title = {Optimization with First-Order Surrogate Functions},

  publisher = {arXiv},

  year = {2013},

  copyright = {arXiv.org perpetual, non-exclusive license}
}



@misc{https://doi.org/10.48550/arxiv.1806.09429,
  doi = {10.48550/ARXIV.1806.09429},

  url = {https://arxiv.org/abs/1806.09429},

  author = {Mishchenko, Konstantin and Iutzeler, Franck and Malick, Jérôme},

  keywords = {Optimization and Control (math.OC), Machine Learning (stat.ML), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences},

  title = {A Distributed Flexible Delay-tolerant Proximal Gradient Algorithm},

  publisher = {arXiv},

  year = {2018},

  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1905.11535,
  doi = {10.48550/ARXIV.1905.11535},

  url = {https://arxiv.org/abs/1905.11535},

  author = {Mishchenko, Konstantin and Richtárik, Peter},

  keywords = {Optimization and Control (math.OC), FOS: Mathematics, FOS: Mathematics},

  title = {A Stochastic Decoupling Method for Minimizing the Sum of Smooth and Non-Smooth Functions},

  publisher = {arXiv},

  year = {2019},

  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1209.1873,
  doi = {10.48550/ARXIV.1209.1873},

  url = {https://arxiv.org/abs/1209.1873},

  author = {Shalev-Shwartz, Shai and Zhang, Tong},

  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), Optimization and Control (math.OC), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},

  title = {Stochastic Dual Coordinate Ascent Methods for Regularized Loss Minimization},

  publisher = {arXiv},

  year = {2012},

  copyright = {arXiv.org perpetual, non-exclusive license}
}
